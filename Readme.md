# Fatigue Level Classifier ğŸ§ ğŸ’¤

## Overview

This project focuses on predicting the **fatigue level** of individuals based on various features. The dataset, sourced from **Kaggle**, is suitable for both **regression** and **classification** models. However, we specifically targeted classification, using the **Fatigue_Level** feature to categorize individuals into three groups: **low**, **moderate**, and **high** fatigue.

The goal of this project is to predict the **Fatigue Level** of a person based on their lifestyle data, such as sleep, stress, caffeine intake, etc.

## Data Description ğŸ“Š

The dataset consists of several important features that contribute to the prediction of the fatigue level:

- **Features for Regression Models**: The dataset includes columns like `System_Recommendation` and `Decision_Fatigue_Score`, but these were dropped during preprocessing. 
- **Target Variable**: The **Fatigue_Level** feature, which includes three categories:
  - Low ğŸ’¤
  - Moderate âš¡
  - High ğŸ”¥

### Data Preprocessing ğŸ”§

Weâ€™ve applied various techniques to preprocess the data and ensure itâ€™s ready for machine learning models:

- **Handling Missing Values**: We filled missing values using the `mode()` for categorical data and `mean()` for numerical data.
- **Encoding**: One-hot encoding and label encoding were applied to categorical variables.
- **Scaling**: MinMaxScaler was used to scale numerical features to a range of 0 to 1.

### Feature Engineering âœ¨

Several new features were created to enhance the modelâ€™s ability to predict fatigue:

- **Sleep Debt**: 
  - Assumption: Ideal sleep time is 8 hours.
  - Formula: `Sleep_Debt = 8 - Sleep_Hours_Last_Night`
  
- **Sleep and Caffeine Interaction**:
  - Formula: `Sleep_Caffeine_Interaction = Sleep_Hours_Last_Night * Caffeine_Intake_Cups`

- **Stress and Cognitive Load Interaction**:
  - Formula: `Stress_Cognitive_Interaction = Stress_Level_1_10 * Cognitive_Load_Score`

- **Task Completion Time**:
  - Formula: `Task_Completion_Time = Decisions_Made * Avg_Decision_Time_sec`

### Feature Selection and Transformation ğŸ”

To ensure we're only using the most relevant features, we implemented:

- **Random Forest Feature Importance**: We used the feature importance method of Random Forest to select features with an importance score greater than 0.01.
- **Skewness Check**: Features with skewness greater than 0.70 were transformed using the **log** function to make them more normal.

### Models Used ğŸ¤–

We tried three different models for classification:

1. **Decision Tree**
2. **Random Forest**
3. **XGBoost**

### Evaluation and Metrics ğŸ“ˆ

The model performance was evaluated based on the **recall** metric, as the main focus is identifying **True Positives** (people with high fatigue). 

After comparing all models, **XGBoost** outperformed the others in terms of recall, making it the best choice for this project.

---

## Project Structure ğŸ“‚

Hereâ€™s the structure of the project:

Fatigue-Level-Classifier/
â”œâ”€â”€ Data/ # Contains all data files
â”‚ â”œâ”€â”€ Engineered_Data/ # Features and transformed data
â”‚ â”œâ”€â”€ Preprocessed_Data/ # Cleaned and processed data
â”‚ â”œâ”€â”€ Raw_Data/ # Original raw data from Kaggle
â”‚ â”œâ”€â”€ Logging/ # Logs for tracking model training
â”‚ â”œâ”€â”€ Metrics/ # Model performance metrics
â”‚ â”œâ”€â”€ Models/ # Trained models
â”‚ â””â”€â”€ Best_Model/ # The best performing model
â”œâ”€â”€ Notebook/ # Jupyter Notebooks for analysis and experimentation
â”‚ â”œâ”€â”€ data_analysis.ipynb # Data analysis and visualization
â”‚ â”œâ”€â”€ data_loader.ipynb # Data loading and exploration
â”‚ â”œâ”€â”€ engineering.ipynb # Feature engineering and transformations
â”‚ â”œâ”€â”€ preprocessing.ipynb # Data preprocessing and cleaning
â”‚ â”œâ”€â”€ testing.ipynb # Model testing and evaluation
â”‚ â””â”€â”€ training.ipynb # Model training and hyperparameter tuning
â”œâ”€â”€ Scripts/ # Python scripts for automated tasks
â”‚ â”œâ”€â”€ data_analysis.py # Script for data analysis
â”‚ â”œâ”€â”€ data_engineering.py # Feature engineering script
â”‚ â”œâ”€â”€ data_loader.py # Data loading and preparation
â”‚ â”œâ”€â”€ data_preprocessing.py # Script for data cleaning and processing
â”‚ â”œâ”€â”€ model_testing.py # Script for model testing and evaluation
â”‚ â””â”€â”€ model_training.py # Script for model training
â”œâ”€â”€ src/ # Source code
â”‚ â”œâ”€â”€ pycache/ # Python cache files
â”‚ â”œâ”€â”€ data_analysis.py # Core data analysis functions
â”‚ â”œâ”€â”€ data_engineering.py # Core feature engineering functions
â”‚ â”œâ”€â”€ data_loader.py # Data loading functions
â”‚ â”œâ”€â”€ data_preprocessing.py # Data preprocessing functions
â”‚ â”œâ”€â”€ model_testing.py # Functions for model testing
â”‚ â””â”€â”€ model_training.py # Functions for model training
â”œâ”€â”€ requirements.txt # List of Python dependencies
â”œâ”€â”€ README.md # Project overview and instructions
â””â”€â”€ .gitignore # Git ignore file to exclude unnecessary files


### Explanation:

- **Data/**: This folder contains all the data files, including raw data, preprocessed data, engineered features, and model logs.
- **Notebook/**: Jupyter Notebooks where all the data analysis, feature engineering, and model training are explored interactively.
- **Scripts/**: Python scripts for running tasks in a non-interactive way, such as data loading, feature engineering, and model training/testing.
- **src/**: Source code for various functions and modules used throughout the project.
- **requirements.txt**: A file listing the Python libraries required to run the project.
- **README.md**: This file, providing an overview of the project.
- **.gitignore**: A file to tell Git which files/folders to ignore during version control (e.g., virtual environments, cache files).